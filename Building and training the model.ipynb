{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the data processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_train\n",
    "%store -r x_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "%store -r yy\n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Deep Learning frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 76,802\n",
      "Trainable params: 76,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to evaluate the test data before the network has been trained. This will show how training the model improves the predictions. (If the model has been trained in this session the accuracy will be high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training accuracy: 91.3793%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by fitting it to the training data. Go through 100 iterations to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1623 samples, validate on 406 samples\n",
      "Epoch 1/100\n",
      "1623/1623 [==============================] - 0s 216us/step - loss: 1.9447 - accuracy: 0.8343 - val_loss: 1.3154 - val_accuracy: 0.8990\n",
      "Epoch 2/100\n",
      "1623/1623 [==============================] - 0s 215us/step - loss: 1.3706 - accuracy: 0.8392 - val_loss: 0.6475 - val_accuracy: 0.9039\n",
      "Epoch 3/100\n",
      "1623/1623 [==============================] - 0s 211us/step - loss: 0.9305 - accuracy: 0.8564 - val_loss: 0.4699 - val_accuracy: 0.9064\n",
      "Epoch 4/100\n",
      "1623/1623 [==============================] - 0s 210us/step - loss: 0.6885 - accuracy: 0.8651 - val_loss: 0.3149 - val_accuracy: 0.9163\n",
      "Epoch 5/100\n",
      "1623/1623 [==============================] - 0s 213us/step - loss: 0.5344 - accuracy: 0.8792 - val_loss: 0.3551 - val_accuracy: 0.9064\n",
      "Epoch 6/100\n",
      "1623/1623 [==============================] - 0s 215us/step - loss: 0.4469 - accuracy: 0.8743 - val_loss: 0.3427 - val_accuracy: 0.9064\n",
      "Epoch 7/100\n",
      "1623/1623 [==============================] - 0s 213us/step - loss: 0.4042 - accuracy: 0.8780 - val_loss: 0.3144 - val_accuracy: 0.9138\n",
      "Epoch 8/100\n",
      "1623/1623 [==============================] - 0s 211us/step - loss: 0.3811 - accuracy: 0.8768 - val_loss: 0.3088 - val_accuracy: 0.9113\n",
      "Epoch 9/100\n",
      "1623/1623 [==============================] - 0s 212us/step - loss: 0.3175 - accuracy: 0.8953 - val_loss: 0.3322 - val_accuracy: 0.9015\n",
      "Epoch 10/100\n",
      "1623/1623 [==============================] - 0s 214us/step - loss: 0.3164 - accuracy: 0.8885 - val_loss: 0.3204 - val_accuracy: 0.9212\n",
      "Epoch 11/100\n",
      "1623/1623 [==============================] - 0s 212us/step - loss: 0.3086 - accuracy: 0.9014 - val_loss: 0.3219 - val_accuracy: 0.9163\n",
      "Epoch 12/100\n",
      "1623/1623 [==============================] - 0s 214us/step - loss: 0.2655 - accuracy: 0.9088 - val_loss: 0.3063 - val_accuracy: 0.9236\n",
      "Epoch 13/100\n",
      "1623/1623 [==============================] - 0s 214us/step - loss: 0.2604 - accuracy: 0.9026 - val_loss: 0.3040 - val_accuracy: 0.9261\n",
      "Epoch 14/100\n",
      "1623/1623 [==============================] - 0s 220us/step - loss: 0.2713 - accuracy: 0.9051 - val_loss: 0.2898 - val_accuracy: 0.9212\n",
      "Epoch 15/100\n",
      "1623/1623 [==============================] - 0s 218us/step - loss: 0.2479 - accuracy: 0.9082 - val_loss: 0.2943 - val_accuracy: 0.9138\n",
      "Epoch 16/100\n",
      "1623/1623 [==============================] - 0s 220us/step - loss: 0.2477 - accuracy: 0.9076 - val_loss: 0.2799 - val_accuracy: 0.9163\n",
      "Epoch 17/100\n",
      "1623/1623 [==============================] - 0s 221us/step - loss: 0.2265 - accuracy: 0.9174 - val_loss: 0.3038 - val_accuracy: 0.9113\n",
      "Epoch 18/100\n",
      "1623/1623 [==============================] - 0s 219us/step - loss: 0.2341 - accuracy: 0.9168 - val_loss: 0.2858 - val_accuracy: 0.9113\n",
      "Epoch 19/100\n",
      "1623/1623 [==============================] - 0s 216us/step - loss: 0.2188 - accuracy: 0.9168 - val_loss: 0.2811 - val_accuracy: 0.9089\n",
      "Epoch 20/100\n",
      "1623/1623 [==============================] - 0s 216us/step - loss: 0.2068 - accuracy: 0.9279 - val_loss: 0.3156 - val_accuracy: 0.8966\n",
      "Epoch 21/100\n",
      "1623/1623 [==============================] - 0s 230us/step - loss: 0.2076 - accuracy: 0.9156 - val_loss: 0.2774 - val_accuracy: 0.9113\n",
      "Epoch 22/100\n",
      "1623/1623 [==============================] - 0s 242us/step - loss: 0.2097 - accuracy: 0.9230 - val_loss: 0.2732 - val_accuracy: 0.9089\n",
      "Epoch 23/100\n",
      "1623/1623 [==============================] - 0s 243us/step - loss: 0.2167 - accuracy: 0.9217 - val_loss: 0.2900 - val_accuracy: 0.9089\n",
      "Epoch 24/100\n",
      "1623/1623 [==============================] - 0s 233us/step - loss: 0.2190 - accuracy: 0.9199 - val_loss: 0.2733 - val_accuracy: 0.9163\n",
      "Epoch 25/100\n",
      "1623/1623 [==============================] - 0s 240us/step - loss: 0.1987 - accuracy: 0.9261 - val_loss: 0.2695 - val_accuracy: 0.9163\n",
      "Epoch 26/100\n",
      "1623/1623 [==============================] - 0s 246us/step - loss: 0.1932 - accuracy: 0.9310 - val_loss: 0.2772 - val_accuracy: 0.9212\n",
      "Epoch 27/100\n",
      "1623/1623 [==============================] - 0s 248us/step - loss: 0.1882 - accuracy: 0.9328 - val_loss: 0.2812 - val_accuracy: 0.9187\n",
      "Epoch 28/100\n",
      "1623/1623 [==============================] - 0s 244us/step - loss: 0.1874 - accuracy: 0.9298 - val_loss: 0.2691 - val_accuracy: 0.9138\n",
      "Epoch 29/100\n",
      "1623/1623 [==============================] - 0s 249us/step - loss: 0.2069 - accuracy: 0.9254 - val_loss: 0.2755 - val_accuracy: 0.9163\n",
      "Epoch 30/100\n",
      "1623/1623 [==============================] - 0s 243us/step - loss: 0.1815 - accuracy: 0.9341 - val_loss: 0.2731 - val_accuracy: 0.9187\n",
      "Epoch 31/100\n",
      "1623/1623 [==============================] - 0s 245us/step - loss: 0.1775 - accuracy: 0.9372 - val_loss: 0.2805 - val_accuracy: 0.9138\n",
      "Epoch 32/100\n",
      "1623/1623 [==============================] - 0s 240us/step - loss: 0.1678 - accuracy: 0.9328 - val_loss: 0.2679 - val_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "1623/1623 [==============================] - 0s 246us/step - loss: 0.1687 - accuracy: 0.9415 - val_loss: 0.2720 - val_accuracy: 0.9163\n",
      "Epoch 34/100\n",
      "1623/1623 [==============================] - 0s 243us/step - loss: 0.1712 - accuracy: 0.9384 - val_loss: 0.2822 - val_accuracy: 0.9113\n",
      "Epoch 35/100\n",
      "1623/1623 [==============================] - 0s 249us/step - loss: 0.1682 - accuracy: 0.9372 - val_loss: 0.2892 - val_accuracy: 0.9163\n",
      "Epoch 36/100\n",
      "1623/1623 [==============================] - 0s 254us/step - loss: 0.1670 - accuracy: 0.9384 - val_loss: 0.3012 - val_accuracy: 0.9138\n",
      "Epoch 37/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.1721 - accuracy: 0.9396 - val_loss: 0.3085 - val_accuracy: 0.9113\n",
      "Epoch 38/100\n",
      "1623/1623 [==============================] - 0s 255us/step - loss: 0.1642 - accuracy: 0.9353 - val_loss: 0.3187 - val_accuracy: 0.9089\n",
      "Epoch 39/100\n",
      "1623/1623 [==============================] - 0s 247us/step - loss: 0.1624 - accuracy: 0.9378 - val_loss: 0.3040 - val_accuracy: 0.9138\n",
      "Epoch 40/100\n",
      "1623/1623 [==============================] - 0s 248us/step - loss: 0.1619 - accuracy: 0.9445 - val_loss: 0.3050 - val_accuracy: 0.9187\n",
      "Epoch 41/100\n",
      "1623/1623 [==============================] - 0s 265us/step - loss: 0.1620 - accuracy: 0.9384 - val_loss: 0.2937 - val_accuracy: 0.9163\n",
      "Epoch 42/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.1472 - accuracy: 0.9470 - val_loss: 0.3200 - val_accuracy: 0.9163\n",
      "Epoch 43/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.1359 - accuracy: 0.9501 - val_loss: 0.3224 - val_accuracy: 0.9163\n",
      "Epoch 44/100\n",
      "1623/1623 [==============================] - 0s 259us/step - loss: 0.1523 - accuracy: 0.9415 - val_loss: 0.3156 - val_accuracy: 0.9163\n",
      "Epoch 45/100\n",
      "1623/1623 [==============================] - 0s 257us/step - loss: 0.1496 - accuracy: 0.9482 - val_loss: 0.3274 - val_accuracy: 0.9163\n",
      "Epoch 46/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.1368 - accuracy: 0.9489 - val_loss: 0.3140 - val_accuracy: 0.9138\n",
      "Epoch 47/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.1420 - accuracy: 0.9415 - val_loss: 0.3230 - val_accuracy: 0.9064\n",
      "Epoch 48/100\n",
      "1623/1623 [==============================] - 0s 264us/step - loss: 0.1401 - accuracy: 0.9501 - val_loss: 0.3267 - val_accuracy: 0.9163\n",
      "Epoch 49/100\n",
      "1623/1623 [==============================] - 0s 260us/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 0.3427 - val_accuracy: 0.9187\n",
      "Epoch 50/100\n",
      "1623/1623 [==============================] - 0s 249us/step - loss: 0.1356 - accuracy: 0.9452 - val_loss: 0.3190 - val_accuracy: 0.9163\n",
      "Epoch 51/100\n",
      "1623/1623 [==============================] - 0s 249us/step - loss: 0.1297 - accuracy: 0.9532 - val_loss: 0.3259 - val_accuracy: 0.9187\n",
      "Epoch 52/100\n",
      "1623/1623 [==============================] - 0s 251us/step - loss: 0.1272 - accuracy: 0.9563 - val_loss: 0.3152 - val_accuracy: 0.9187\n",
      "Epoch 53/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.1138 - accuracy: 0.9587 - val_loss: 0.3512 - val_accuracy: 0.9138\n",
      "Epoch 54/100\n",
      "1623/1623 [==============================] - 0s 257us/step - loss: 0.1274 - accuracy: 0.9495 - val_loss: 0.3326 - val_accuracy: 0.9039\n",
      "Epoch 55/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.1213 - accuracy: 0.9581 - val_loss: 0.3399 - val_accuracy: 0.9138\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623/1623 [==============================] - 0s 262us/step - loss: 0.1173 - accuracy: 0.9519 - val_loss: 0.3308 - val_accuracy: 0.9187\n",
      "Epoch 57/100\n",
      "1623/1623 [==============================] - 0s 254us/step - loss: 0.1263 - accuracy: 0.9501 - val_loss: 0.3438 - val_accuracy: 0.9089\n",
      "Epoch 58/100\n",
      "1623/1623 [==============================] - 0s 251us/step - loss: 0.1089 - accuracy: 0.9538 - val_loss: 0.3337 - val_accuracy: 0.9089\n",
      "Epoch 59/100\n",
      "1623/1623 [==============================] - 0s 252us/step - loss: 0.1178 - accuracy: 0.9513 - val_loss: 0.3206 - val_accuracy: 0.9163\n",
      "Epoch 60/100\n",
      "1623/1623 [==============================] - 0s 251us/step - loss: 0.1148 - accuracy: 0.9600 - val_loss: 0.3962 - val_accuracy: 0.9064\n",
      "Epoch 61/100\n",
      "1623/1623 [==============================] - 0s 248us/step - loss: 0.1240 - accuracy: 0.9532 - val_loss: 0.3651 - val_accuracy: 0.9138\n",
      "Epoch 62/100\n",
      "1623/1623 [==============================] - 0s 257us/step - loss: 0.1140 - accuracy: 0.9581 - val_loss: 0.3831 - val_accuracy: 0.9163\n",
      "Epoch 63/100\n",
      "1623/1623 [==============================] - 0s 263us/step - loss: 0.1234 - accuracy: 0.9575 - val_loss: 0.3776 - val_accuracy: 0.9163\n",
      "Epoch 64/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.1221 - accuracy: 0.9575 - val_loss: 0.3762 - val_accuracy: 0.9089\n",
      "Epoch 65/100\n",
      "1623/1623 [==============================] - 0s 251us/step - loss: 0.1200 - accuracy: 0.9556 - val_loss: 0.3747 - val_accuracy: 0.9138\n",
      "Epoch 66/100\n",
      "1623/1623 [==============================] - 0s 254us/step - loss: 0.0976 - accuracy: 0.9630 - val_loss: 0.3881 - val_accuracy: 0.9113\n",
      "Epoch 67/100\n",
      "1623/1623 [==============================] - 0s 259us/step - loss: 0.1026 - accuracy: 0.9563 - val_loss: 0.4090 - val_accuracy: 0.9138\n",
      "Epoch 68/100\n",
      "1623/1623 [==============================] - 0s 259us/step - loss: 0.0972 - accuracy: 0.9618 - val_loss: 0.4106 - val_accuracy: 0.9163\n",
      "Epoch 69/100\n",
      "1623/1623 [==============================] - 0s 267us/step - loss: 0.1046 - accuracy: 0.9600 - val_loss: 0.4156 - val_accuracy: 0.9163\n",
      "Epoch 70/100\n",
      "1623/1623 [==============================] - 0s 264us/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 0.3867 - val_accuracy: 0.9163\n",
      "Epoch 71/100\n",
      "1623/1623 [==============================] - 0s 259us/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.3949 - val_accuracy: 0.9138\n",
      "Epoch 72/100\n",
      "1623/1623 [==============================] - 0s 264us/step - loss: 0.0880 - accuracy: 0.9680 - val_loss: 0.4264 - val_accuracy: 0.9089\n",
      "Epoch 73/100\n",
      "1623/1623 [==============================] - 0s 262us/step - loss: 0.0872 - accuracy: 0.9686 - val_loss: 0.4357 - val_accuracy: 0.9113\n",
      "Epoch 74/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.0967 - accuracy: 0.9661 - val_loss: 0.4308 - val_accuracy: 0.9138\n",
      "Epoch 75/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.0746 - accuracy: 0.9729 - val_loss: 0.4615 - val_accuracy: 0.9138\n",
      "Epoch 76/100\n",
      "1623/1623 [==============================] - 0s 267us/step - loss: 0.0871 - accuracy: 0.9692 - val_loss: 0.4900 - val_accuracy: 0.9089\n",
      "Epoch 77/100\n",
      "1623/1623 [==============================] - 0s 255us/step - loss: 0.0986 - accuracy: 0.9673 - val_loss: 0.4481 - val_accuracy: 0.9138\n",
      "Epoch 78/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.0850 - accuracy: 0.9747 - val_loss: 0.4828 - val_accuracy: 0.9089\n",
      "Epoch 79/100\n",
      "1623/1623 [==============================] - 0s 260us/step - loss: 0.0912 - accuracy: 0.9686 - val_loss: 0.4823 - val_accuracy: 0.9089\n",
      "Epoch 80/100\n",
      "1623/1623 [==============================] - 0s 255us/step - loss: 0.0905 - accuracy: 0.9686 - val_loss: 0.4832 - val_accuracy: 0.9015\n",
      "Epoch 81/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.4815 - val_accuracy: 0.9089\n",
      "Epoch 82/100\n",
      "1623/1623 [==============================] - 0s 255us/step - loss: 0.0737 - accuracy: 0.9809 - val_loss: 0.4993 - val_accuracy: 0.9064\n",
      "Epoch 83/100\n",
      "1623/1623 [==============================] - 0s 257us/step - loss: 0.0724 - accuracy: 0.9772 - val_loss: 0.4794 - val_accuracy: 0.9187\n",
      "Epoch 84/100\n",
      "1623/1623 [==============================] - 0s 257us/step - loss: 0.0681 - accuracy: 0.9778 - val_loss: 0.5008 - val_accuracy: 0.9113\n",
      "Epoch 85/100\n",
      "1623/1623 [==============================] - 0s 261us/step - loss: 0.0680 - accuracy: 0.9766 - val_loss: 0.4900 - val_accuracy: 0.9163\n",
      "Epoch 86/100\n",
      "1623/1623 [==============================] - 0s 258us/step - loss: 0.0819 - accuracy: 0.9710 - val_loss: 0.4498 - val_accuracy: 0.9236\n",
      "Epoch 87/100\n",
      "1623/1623 [==============================] - 0s 261us/step - loss: 0.0882 - accuracy: 0.9704 - val_loss: 0.6164 - val_accuracy: 0.9187\n",
      "Epoch 88/100\n",
      "1623/1623 [==============================] - 0s 265us/step - loss: 0.0786 - accuracy: 0.9754 - val_loss: 0.5451 - val_accuracy: 0.9113\n",
      "Epoch 89/100\n",
      "1623/1623 [==============================] - 0s 260us/step - loss: 0.0631 - accuracy: 0.9784 - val_loss: 0.5728 - val_accuracy: 0.9138\n",
      "Epoch 90/100\n",
      "1623/1623 [==============================] - 0s 256us/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.5491 - val_accuracy: 0.9113\n",
      "Epoch 91/100\n",
      "1623/1623 [==============================] - 0s 266us/step - loss: 0.0744 - accuracy: 0.9784 - val_loss: 0.5068 - val_accuracy: 0.9187\n",
      "Epoch 92/100\n",
      "1623/1623 [==============================] - 0s 265us/step - loss: 0.0667 - accuracy: 0.9760 - val_loss: 0.5336 - val_accuracy: 0.9138\n",
      "Epoch 93/100\n",
      "1623/1623 [==============================] - 0s 274us/step - loss: 0.0703 - accuracy: 0.9766 - val_loss: 0.5300 - val_accuracy: 0.9187\n",
      "Epoch 94/100\n",
      "1623/1623 [==============================] - 0s 276us/step - loss: 0.0696 - accuracy: 0.9797 - val_loss: 0.5686 - val_accuracy: 0.9138\n",
      "Epoch 95/100\n",
      "1623/1623 [==============================] - 0s 273us/step - loss: 0.0737 - accuracy: 0.9741 - val_loss: 0.5730 - val_accuracy: 0.9138\n",
      "Epoch 96/100\n",
      "1623/1623 [==============================] - 0s 273us/step - loss: 0.0635 - accuracy: 0.9772 - val_loss: 0.5721 - val_accuracy: 0.9212\n",
      "Epoch 97/100\n",
      "1623/1623 [==============================] - 0s 265us/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.6127 - val_accuracy: 0.9064\n",
      "Epoch 98/100\n",
      "1623/1623 [==============================] - 0s 264us/step - loss: 0.0491 - accuracy: 0.9809 - val_loss: 0.6255 - val_accuracy: 0.9113\n",
      "Epoch 99/100\n",
      "1623/1623 [==============================] - 0s 267us/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.5710 - val_accuracy: 0.9089\n",
      "Epoch 100/100\n",
      "1623/1623 [==============================] - 0s 270us/step - loss: 0.0855 - accuracy: 0.9735 - val_loss: 0.5556 - val_accuracy: 0.9138\n",
      "Training completed in time:  0:00:40.413735\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on both the train set and the test set. This should give an indication of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9926062822341919\n",
      "Testing Accuracy:  0.9137930870056152\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the classifier, use the dame extract features function as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: emergency \n",
      "\n",
      "emergency \t\t :  1.00000000000000000000000000000000\n",
      "non_emergency \t\t :  0.00000001810440863891926710493863\n"
     ]
    }
   ],
   "source": [
    "emergency_test_dataset_path = '../Datasets/kaggle/ambulance/sound_1.wav'\n",
    "\n",
    "print_prediction(emergency_test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
